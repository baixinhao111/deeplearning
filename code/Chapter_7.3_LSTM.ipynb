{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入相关模块\n",
    "import os \n",
    "import glob \n",
    "import time\n",
    "import subprocess \n",
    "import pickle\n",
    "import numpy as np\n",
    "from pickle import dump, load \n",
    "from music21 import converter, instrument, note, chord, stream\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as DataSet\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 读取作曲任务所需序列数据\n",
    "musicians = load(open('../dataset/LSTM/musicians', 'rb'))\n",
    "namelist = load(open('../dataset/LSTM/namelist', 'rb'))\n",
    "seqs = load(open('../dataset/LSTM/seqs', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始序列\n",
      "['G#4', 'G4', 'F4', 'D4', 'E-4', 'D4', 'B3', 'G3', 'G#3', 'G3', 'F3', 'D3', 'E-3', 'D3', 'B2', 'G2', 'G#2', 'G2', 'F2', 'D2', 'E-2', 'D2', 'C2', 'G1', 'C2', 'G1', '3.5.8', 'C2', 'G1', 'C2', '7', 'G1', '2.5.7', 'B1', 'G#4', 'G4', 'F4', 'D4', 'E-4', 'D4', 'B3', 'G3', 'G#3', 'G3', 'F3', 'D3', 'E-3', 'D3', 'B2', 'G2', 'G#2', 'G2', 'F2', 'D2', 'E-2', 'D2', 'C2', 'G1', 'C2', 'G1', '3.5.8', 'C2', 'G1', 'C2', '7', 'G1', '2.5.7', 'B1', 'G#6', 'G#5', 'G6', 'G5', 'F6', 'F5', 'D6', 'D5', 'E-6', 'E-5', 'D6', 'D5', 'B5', 'B4', 'G5', 'G4', 'G#5', 'G#4', 'G5', 'G4', 'F5', 'F4', 'D5', 'D4', 'E-5', 'E-4', 'D5', 'D4', 'B4', 'B3', 'G4']\n",
      "\n",
      " 编码后的结果\n",
      "[49, 11, 23, 15, 26, 15, 42, 73, 58, 73, 72, 39, 71, 39, 40, 84, 108, 84, 48, 29, 154, 29, 176, 218, 176, 218, 265, 176, 218, 176, 139, 218, 200, 144, 49, 11, 23, 15, 26, 15, 42, 73, 58, 73, 72, 39, 71, 39, 40, 84, 108, 84, 48, 29, 154, 29, 176, 218, 176, 218, 265, 176, 218, 176, 139, 218, 200, 144, 146, 86, 161, 1, 54, 47, 46, 2, 165, 4, 46, 2, 162, 3, 1, 11, 86, 49, 1, 11, 47, 23, 2, 15, 4, 26, 2, 15, 3, 42, 11]\n"
     ]
    }
   ],
   "source": [
    "# 定义序列编码函数\n",
    "def seq_encode(seqs):\n",
    "    seq2idx = {}\n",
    "    seqs_digit = []\n",
    "    \n",
    "    i = 1\n",
    "    for seq in seqs:\n",
    "        for s in seq:\n",
    "            if seq2idx.get(s) == None:\n",
    "                seq2idx[s] = i\n",
    "                i += 1\n",
    "                \n",
    "    for seq in seqs:\n",
    "        seq_digit = []\n",
    "        for s in seq:\n",
    "            seq_digit.append(seq2idx[s])\n",
    "        seqs_digit.append(seq_digit)\n",
    "    return seq2idx, seqs_digit\n",
    "\n",
    "seq2idx, seqs_digit = seq_encode(seqs)\n",
    "print(\"原始序列\")\n",
    "print(seqs[123][1:100])\n",
    "print(\"\\n 编码后的结果\")\n",
    "print(seqs_digit[123][1:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始序列\n",
      "['albeniz', 'albeniz', 'beethoven', 'beethoven', 'beethoven', 'beethoven', 'beethoven', 'beethoven', 'beethoven', 'beethoven', 'beethoven', 'beethoven', 'beethoven', 'beethoven', 'beethoven', 'beethoven', 'beethoven', 'beethoven', 'beethoven', 'beethoven']\n",
      "\n",
      " 编码后的结果\n",
      "[0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "### 定义音乐家姓名编码函数\n",
    "def musician_encode(namelist):\n",
    "    # 创建音乐家编码字典\n",
    "    name2idx = {}\n",
    "    i = 0\n",
    "    for name in namelist:\n",
    "        if name2idx.get(name) == None:\n",
    "                name2idx[name] = i\n",
    "                i += 1\n",
    "                \n",
    "    # 对音乐家列表进行编码\n",
    "    namelist_digit = []\n",
    "    for name in namelist:\n",
    "        namelist_digit.append(name2idx[name])\n",
    "    return name2idx, namelist_digit\n",
    "\n",
    "name2idx, namelist_digit = musician_encode(namelist)\n",
    "print(\"原始序列\")\n",
    "print(namelist[25:45])\n",
    "print(\"\\n 编码后的结果\")\n",
    "print(namelist_digit[25:45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([614, 9])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将音乐家姓名编码转为one-hot形式\n",
    "namelist_digit = F.one_hot(torch.tensor(namelist_digit))\n",
    "namelist_digit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始乐曲（部分）: \n",
      "['G#4', 'G4', 'F4', 'D4', 'E-4', 'D4', 'B3', 'G3', 'G#3', 'G3', 'F3', 'D3', 'E-3', 'D3', 'B2', 'G2', 'G#2', 'G2', 'F2', 'D2', 'E-2', 'D2', 'C2', 'G1', 'C2', 'G1', '3.5.8', 'C2', 'G1', 'C2', '7', 'G1', '2.5.7', 'B1', 'G#4', 'G4', 'F4', 'D4', 'E-4', 'D4', 'B3', 'G3', 'G#3', 'G3', 'F3', 'D3', 'E-3', 'D3', 'B2']\n",
      "变量X（音符序列）: \n",
      "[96, 39, 138, 72, 62, 56, 50, 102, 15, 139, 26, 102, 15, 62, 56, 96, 72, 48, 127, 157, 96, 39, 138, 72, 62, 56, 50, 102, 15, 139, 26, 102, 15, 62, 56, 96, 72, 48, 127, 157, 96, 39, 138, 72, 15, 2, 50, 56, 23, 15, 11, 26, 23, 15, 15, 56, 56, 72, 9, 47, 23, 43, 67, 6, 41, 9, 15, 6, 41, 111, 23, 2, 67, 41, 72, 5, 176, 56, 5, 71, 41, 66, 6, 41, 35, 56, 6, 24, 73, 41, 66, 11, 56, 75, 58, 23, 48, 40, 67, 43, 56, 39, 67, 43, 96, 39, 138, 72, 62, 50, 56, 102, 15, 139, 26, 102, 15, 62, 56, 96, 72, 48, 127, 157, 96, 39, 138, 72, 62, 56, 50, 102, 15, 139, 26, 102, 15, 62, 56, 96, 72, 48, 127, 157, 96, 39, 138, 72, 2, 15, 56, 50, 23, 15, 11, 26, 23, 15, 15, 56, 56, 72, 9, 47, 23, 67, 43, 6, 41, 9, 15, 6, 41, 111, 2, 23, 67, 41, 72, 5, 176, 5, 56, 71, 41, 66, 6, 41, 35, 56, 24, 6, 73, 41, 66, 11, 56, 75, 58, 23, 48, 40, 67, 43, 56, 39, 67, 43, 50, 43, 177, 58, 9, 39, 56, 11, 23, 41, 50, 43, 56, 39, 176, 9, 58, 71, 56, 23, 26, 41, 50, 43, 56, 39, 71, 82, 58, 9, 66, 24, 29, 9, 58, 72, 23, 58, 9, 29, 50, 43, 50, 43, 13, 50, 70, 50, 58, 154, 49, 73, 11, 97, 73, 102, 56, 11, 1, 26, 71, 4, 11, 47, 49, 4, 11, 5, 47, 73, 26, 36, 41, 2, 15, 56, 84, 9, 15, 5, 26, 9, 15, 11, 9, 35, 15, 73, 11, 1, 26, 43, 4, 11, 47, 49, 36, 11, 47, 5, 26, 73, 11, 41, 4, 2, 15, 84, 56, 9, 15, 5, 26, 9, 15, 19, 73, 56, 31, 67, 96, 43, 73, 31, 72, 19, 66, 245, 39, 245, 43, 176, 19, 50, 31, 70, 80, 50, 33, 43, 79, 39, 19, 176, 66, 31, 72, 118, 43, 73, 33, 67, 122, 56, 34, 42, 140, 43, 41, 80, 56, 53, 67, 141, 58, 178, 73, 104, 74, 12, 72, 53, 71, 96, 39, 138, 72, 62, 50, 56, 102, 15, 139, 26, 102, 15, 62, 56, 96, 72, 48, 127, 157, 96, 39, 138, 72, 62, 56, 50, 102, 15, 139, 26, 102, 15, 62, 96, 96, 34, 48, 127, 157, 84, 50, 70, 96, 59, 138, 36, 62, 72, 48, 97, 73, 154, 102, 58, 94, 56, 29, 139, 42, 102, 73, 76, 138, 62, 139, 138, 79, 62, 63, 138, 118, 62, 33, 76, 84, 73, 102, 67, 48, 94, 56, 139, 42, 133, 120, 41, 139, 56, 102, 33, 97, 139, 62, 78, 138, 140, 96, 50, 39, 138, 72, 15, 2, 56, 177, 5, 67, 9, 73, 6, 72, 36, 71, 50, 102, 39, 26, 1, 43, 177, 23, 39, 11, 71, 33, 72, 149, 50, 73, 61, 58, 5, 177, 67, 9, 73, 5, 2, 31, 72, 19, 71, 23, 4, 50, 39, 26, 43, 15, 47, 50, 177, 26, 43, 23, 39, 36, 71, 59, 50, 66, 31, 72, 9, 177, 73, 6, 72, 9, 5, 35, 71, 53, 39, 50, 26, 2, 43, 15, 50, 32, 192, 62, 50, 32, 43, 118, 75, 33, 39, 36, 71, 34, 72, 32, 73, 67, 30, 31, 35, 33, 15, 36, 26, 34, 23, 32, 45, 33, 177, 119, 39, 127, 23, 2, 9, 15, 2, 9, 11, 23, 5, 24, 41, 5, 6, 23, 67, 119, 15, 73, 80, 41, 56, 5, 26, 67, 26, 9, 4, 73, 15, 2, 67, 15, 6, 74, 41, 96, 73, 43, 23, 31, 72, 70, 19, 50, 84, 79, 43, 50, 23, 70, 6, 47, 5, 102, 23, 9, 2, 15, 2, 9, 11, 23, 5, 24, 41, 5, 6, 23, 67, 119, 15, 73, 80, 41, 56, 5, 26, 67, 26, 9, 4, 73, 15, 2, 67, 15, 6, 74, 41, 96, 73, 43, 23, 31, 72, 70, 19, 50, 84, 41, 24, 43, 50, 23, 70, 67, 41, 23, 102, 72, 67, 41, 43, 15, 56, 58, 56, 26, 74, 56, 26, 77, 234, 71, 74, 56, 50, 72, 41, 108, 71, 28, 75, 102, 58, 56, 26, 77, 234, 71, 74, 56, 50, 41, 72, 108, 71, 98, 102, 75, 56, 94, 71, 26, 139, 43, 41, 95, 72, 23, 120, 39, 15, 96, 73, 11, 130, 41, 5, 138, 23, 47, 102, 6, 47, 5, 23, 9, 2, 15, 2, 9, 11, 23, 5, 24, 41, 6, 5, 23, 67, 119, 15, 73, 80, 41, 56, 5, 26, 67, 26, 9, 4, 73, 15, 2, 67, 15, 6, 74, 41, 96, 73, 43, 31, 23, 72, 70, 19, 50, 84, 24, 41, 43, 50, 23, 70, 67, 23, 41, 102, 72, 41, 67, 43, 15, 56, 58, 26, 56, 74, 56, 26, 234, 77, 71, 56, 74, 50, 41, 72, 108, 71, 75, 28, 102, 58, 26, 56, 77, 234, 71, 56, 74, 50, 72, 41, 108, 71, 98, 102, 75, 56, 94, 71, 26, 139, 43, 41, 95, 72, 23, 120, 39, 15, 96, 73, 11, 130, 41, 5, 138, 23, 47, 102, 6, 5, 47, 23, 9, 2, 15, 9, 2, 11, 23, 5, 24, 41, 6, 5, 23, 67, 119, 15, 73, 80, 41, 56, 5, 26, 67, 26, 4, 9, 73, 15, 2, 67, 15, 6, 74, 41, 96, 73, 43, 31, 23, 72, 70, 19, 50, 84, 24, 41, 43, 50, 23, 72, 70, 71, 96, 50, 39, 138, 72, 62, 56, 102, 15, 139, 26, 102, 15, 62, 56, 96, 72, 48, 127, 157, 96, 39, 138, 72, 62, 50, 56, 102, 15, 139, 26, 102, 15, 62, 56, 96, 72, 48, 127, 157, 96, 39, 138, 72, 2, 15, 56, 50, 23, 15, 11, 26, 23]\n",
      "变量X（作曲家）: \n",
      "[0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "变量Y: \n",
      "15\n"
     ]
    }
   ],
   "source": [
    "### 定义生成训练输入输出序列函数\n",
    "def generate_XY(seqs_digit, namelist, max_len):\n",
    "    X = []\n",
    "    Y = []\n",
    "    i = -1\n",
    "    for seq_digit in seqs_digit:\n",
    "        i += 1\n",
    "        if len(seq_digit) < 1:\n",
    "            continue\n",
    "\n",
    "        # 将每首乐曲的最后一个音符作为Y\n",
    "        Y.append(seq_digit[-1])\n",
    "        # 将最后一个音符之前的部分作为X，并补齐字符\n",
    "        x = seq_digit[:-1] + [0]*(max_len - len(seq_digit))\n",
    "        l = namelist_digit[i].tolist()\n",
    "        X.append(x+l)\n",
    "    # 将所有数据的顺序打乱重排\n",
    "    idx = np.random.permutation(range(len(X)))\n",
    "    X = [X[i] for i in idx]\n",
    "    Y = [Y[i] for i in idx]\n",
    "    return X, Y\n",
    "\n",
    "X, Y = generate_XY(seqs_digit, namelist, 1000)\n",
    "print(\"原始乐曲（部分）: \")\n",
    "print(seqs[123][1:50])\n",
    "print(\"变量X（音符序列）: \")\n",
    "print(X[123][0:999])\n",
    "print(\"变量X（作曲家）: \")\n",
    "print(X[123][-9:])\n",
    "print(\"变量Y: \")\n",
    "print(Y[123])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设定batch size\n",
    "batch_size = 64\n",
    "# 创建Tensor形式的数据集\n",
    "ds = DataSet.TensorDataset(torch.LongTensor(np.array(X, dtype=int)), torch.LongTensor(np.array(Y, dtype=int)))\n",
    "# 形成数据集加载器\n",
    "loader = DataSet.DataLoader(ds, batch_size=batch_size, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### 定义一个LSTM模型类\n",
    "class LSTMNetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size, word_num, embedding_size, hidden_size, num_layers=1):\n",
    "        super(LSTMNetwork, self).__init__()\n",
    "        # 一个embedding层\n",
    "        self.embedding = nn.Embedding(word_num, embedding_size) \n",
    "        # PyTorch的LSTM层，batch_first标识可以让输入的张量的第一个维度表示batch指标\n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_size, num_layers, batch_first=True)\n",
    "        # 输出的全连接层\n",
    "        self.fc = nn.Linear(hidden_size, output_size) \n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.embedding_size = embedding_size\n",
    "    \n",
    "    ### 定义前向计算流程\n",
    "    def forward(self, x2, hidden):\n",
    "        # 先进行embedding层的计算\n",
    "        x = self.embedding(x2)\n",
    "        # 读入隐含层的初始信息\n",
    "        hh = hidden#[0]\n",
    "        # 从输入到隐含层的计算\n",
    "        # x的尺寸为：batch_size，num_step，hidden_size\n",
    "        output, hidden = self.lstm(x, hh)\n",
    "        # 从output中去除最后一个时间步的数值（output中包含了所有时间步的结果）\n",
    "        output = output[:, -1, ...]\n",
    "        # 最后一层全连接网络\n",
    "        output = self.fc(output)\n",
    "        # output的尺寸为：batch_size，output_size\n",
    "        return output\n",
    "    \n",
    "    ### 对隐含单元初始化\n",
    "    def initHidden(self, x1, x1_size, batch_size):\n",
    "        x = self.embedding(x1).cuda()     \n",
    "        # 初始化的隐藏元和记忆元,通常它们的维度是一样的\n",
    "        h1 = Variable(torch.zeros(self.num_layers, batch_size, self.hidden_size)).cuda()\n",
    "        c1 = Variable(torch.zeros(self.num_layers, batch_size, self.hidden_size)).cuda()\n",
    "        # 这里我们要对后面的LSTM模型的隐藏状态进行条件初始化\n",
    "        # 需要借助一个LSTM来获得其在对应音乐家特征向量输入下输出的隐藏状态\n",
    "        _, out = self.lstm(x, (h1, c1)) \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMNetwork(\n",
      "  (embedding): Embedding(456, 256)\n",
      "  (lstm): LSTM(256, 128, batch_first=True)\n",
      "  (fc): Linear(in_features=128, out_features=456, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 获取数据集包含的音符数量\n",
    "seq_size = len(seq2idx.keys())+1\n",
    "# 设定学习率和训练轮数\n",
    "lr = 1e-2\n",
    "epochs = 50\n",
    "# 序列最大长度\n",
    "max_len = 1000\n",
    "# 生成一个简单的LSTM，输入size为999，输出size为seq_size（字符总数）\n",
    "lstm = LSTMNetwork(input_size=max_len-1, output_size=seq_size, word_num=seq_size, embedding_size=256, hidden_size=128)\n",
    "# 转为GPU下的模型\n",
    "lstm = lstm.cuda()\n",
    "#交叉熵损失函数\n",
    "criterion = torch.nn.CrossEntropyLoss() \n",
    "#Adam优化算法\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=lr) \n",
    "#查看模型具体信息\n",
    "print(lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 定义预测准确率的函数\n",
    "def accuracy(pre, label):\n",
    "    #得到每一行（每一个样本）输出值最大元素的下标\n",
    "    pre = torch.max(pre.data, 1)[1]\n",
    "    #将下标与label比较，计算正确的数量\n",
    "    rights = pre.eq(label.data).sum()\n",
    "    #计算正确预测所占百分比\n",
    "    acc = rights.data / len(label)\n",
    "    return acc.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 定义一个tensor分割函数\n",
    "def split_x1_x2(x):\n",
    "    x = x.tolist()\n",
    "    x1 = [x[i][0:999] for i in range(len(x))]\n",
    "    x2 = [x[i][-9:] for i in range(len(x))]\n",
    "    x1 = torch.LongTensor(np.array(x1, dtype=int))\n",
    "    x2 = torch.LongTensor(np.array(x2, dtype=int))\n",
    "    return Variable(x1).cuda(), Variable(x2).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义打印日志函数\n",
    "def print_log(epoch, train_time, train_loss, train_acc, epochs=10):\n",
    "    print(f\"Epoch [{epoch}/{epochs}], time: {train_time:.2f}s, loss: {train_loss:.4f}, acc: {train_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 定义模型训练函数\n",
    "def train(model,optimizer, train_loader, epochs=1):\n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    val_losses = []\n",
    "    val_accs = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        model.train() \n",
    "        # 记录当前epoch开始时间\n",
    "        start = time.time()  \n",
    "        for batch, data in enumerate(train_loader):\n",
    "            # batch为数字，表示已经进行了几个batch\n",
    "            # data为一个二元组，存储了一个样本的输入和标签\n",
    "            x, y = Variable(data[0]), Variable(data[1])\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "            x1, x2 = split_x1_x2(x)\n",
    "            init_hidden = model.initHidden(x2, 9, len(data[0]))\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x1, init_hidden)\n",
    "            y = y.long()\n",
    "            # 计算当前损失\n",
    "            loss = criterion(outputs, y) \n",
    "            train_loss += loss.data.cpu().numpy()  \n",
    "            train_acc += accuracy(outputs, y) \n",
    "            loss.backward() \n",
    "            optimizer.step() \n",
    "            \n",
    "        # 记录当前epoch结束时间\n",
    "        end = time.time()  \n",
    "        # 计算当前epoch的训练耗时 \n",
    "        train_time = end - start\n",
    "        # 计算平均损失\n",
    "        train_loss /= len(train_loader) \n",
    "        # 计算平均准确率 \n",
    "        train_acc /= len(train_loader)              \n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        # 打印训练过程信息\n",
    "        print_log(epoch + 1, train_time, train_loss, train_acc, epochs=epochs)  \n",
    "\n",
    "    return train_losses, train_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], time: 0.74s, loss: 5.6981, acc: 0.0203\n",
      "Epoch [2/50], time: 0.71s, loss: 4.2809, acc: 0.0803\n",
      "Epoch [3/50], time: 0.71s, loss: 3.5172, acc: 0.2931\n",
      "Epoch [4/50], time: 0.71s, loss: 2.8060, acc: 0.4484\n",
      "Epoch [5/50], time: 0.72s, loss: 2.4353, acc: 0.5337\n",
      "Epoch [6/50], time: 0.71s, loss: 2.2336, acc: 0.5528\n",
      "Epoch [7/50], time: 0.71s, loss: 2.1415, acc: 0.5559\n",
      "Epoch [8/50], time: 0.72s, loss: 2.0470, acc: 0.5731\n",
      "Epoch [9/50], time: 0.71s, loss: 2.0751, acc: 0.5691\n",
      "Epoch [10/50], time: 0.71s, loss: 2.0614, acc: 0.5725\n",
      "Epoch [11/50], time: 0.72s, loss: 2.0397, acc: 0.5697\n",
      "Epoch [12/50], time: 0.74s, loss: 2.0669, acc: 0.5644\n",
      "Epoch [13/50], time: 0.72s, loss: 2.0220, acc: 0.5713\n",
      "Epoch [14/50], time: 0.71s, loss: 2.0505, acc: 0.5675\n",
      "Epoch [15/50], time: 0.71s, loss: 2.0284, acc: 0.5709\n",
      "Epoch [16/50], time: 0.71s, loss: 2.0777, acc: 0.5628\n",
      "Epoch [17/50], time: 0.72s, loss: 2.0729, acc: 0.5656\n",
      "Epoch [18/50], time: 0.72s, loss: 2.0124, acc: 0.5713\n",
      "Epoch [19/50], time: 0.72s, loss: 2.1385, acc: 0.5375\n",
      "Epoch [20/50], time: 0.71s, loss: 2.0689, acc: 0.5578\n",
      "Epoch [21/50], time: 0.72s, loss: 2.0113, acc: 0.5763\n",
      "Epoch [22/50], time: 0.72s, loss: 2.0643, acc: 0.5625\n",
      "Epoch [23/50], time: 0.71s, loss: 2.0189, acc: 0.5759\n",
      "Epoch [24/50], time: 0.72s, loss: 2.0179, acc: 0.5759\n",
      "Epoch [25/50], time: 0.72s, loss: 2.0346, acc: 0.5691\n",
      "Epoch [26/50], time: 0.73s, loss: 2.0395, acc: 0.5625\n",
      "Epoch [27/50], time: 0.72s, loss: 2.0782, acc: 0.5556\n",
      "Epoch [28/50], time: 0.72s, loss: 2.0716, acc: 0.5619\n",
      "Epoch [29/50], time: 0.71s, loss: 2.0808, acc: 0.5637\n",
      "Epoch [30/50], time: 0.71s, loss: 2.0345, acc: 0.5675\n",
      "Epoch [31/50], time: 0.71s, loss: 1.9646, acc: 0.5828\n",
      "Epoch [32/50], time: 0.71s, loss: 1.9587, acc: 0.5844\n",
      "Epoch [33/50], time: 0.71s, loss: 1.9882, acc: 0.5791\n",
      "Epoch [34/50], time: 0.71s, loss: 2.0743, acc: 0.5556\n",
      "Epoch [35/50], time: 0.72s, loss: 1.9775, acc: 0.5775\n",
      "Epoch [36/50], time: 0.72s, loss: 2.0418, acc: 0.5594\n",
      "Epoch [37/50], time: 0.71s, loss: 2.0804, acc: 0.5519\n",
      "Epoch [38/50], time: 0.72s, loss: 1.9864, acc: 0.5697\n",
      "Epoch [39/50], time: 0.72s, loss: 2.0295, acc: 0.5678\n",
      "Epoch [40/50], time: 0.71s, loss: 2.0359, acc: 0.5672\n",
      "Epoch [41/50], time: 0.72s, loss: 1.9788, acc: 0.5841\n",
      "Epoch [42/50], time: 0.71s, loss: 2.0593, acc: 0.5475\n",
      "Epoch [43/50], time: 0.71s, loss: 1.9878, acc: 0.5725\n",
      "Epoch [44/50], time: 0.71s, loss: 1.9963, acc: 0.5756\n",
      "Epoch [45/50], time: 0.72s, loss: 1.9585, acc: 0.5791\n",
      "Epoch [46/50], time: 0.72s, loss: 1.9683, acc: 0.5744\n",
      "Epoch [47/50], time: 0.73s, loss: 1.9978, acc: 0.5631\n",
      "Epoch [48/50], time: 0.72s, loss: 1.9960, acc: 0.5756\n",
      "Epoch [49/50], time: 0.72s, loss: 1.9704, acc: 0.5791\n",
      "Epoch [50/50], time: 0.73s, loss: 2.0772, acc: 0.5503\n"
     ]
    }
   ],
   "source": [
    "# 模型训练\n",
    "history = train(lstm, optimizer, loader, epochs=epochs)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 生成指定音乐家的音乐\n",
    "# 导入随机模块\n",
    "import random\n",
    "# 指定音乐家\n",
    "musicianname = 'beethoven'\n",
    "# 获得指定音乐家的数字序号\n",
    "name_digit = name2idx[musicianname]\n",
    "# 将指定音乐家变为输入的one-hot向量\n",
    "name_digit = F.one_hot(torch.tensor(name_digit), num_classes=9)\n",
    "# 用于存储后续模型输入的初始部分音乐序列\n",
    "input_index = []\n",
    "#随机抽取所选音乐家的一段已有乐曲用于后续辅助\n",
    "for i in range(len(seqs)):\n",
    "    if namelist[i] == musicianname:\n",
    "        temp = seqs_digit[i][0:20]\n",
    "        vocab = list(seqs_digit[i])\n",
    "        if random.random() > 0.5:\n",
    "            input_index = seqs_digit[i][0:20]\n",
    "            vocab = list(seqs_digit[i])\n",
    "            break\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "if len(input_index) == 0:\n",
    "    input_index = temp\n",
    "\n",
    "input_index = list(input_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3']\n"
     ]
    }
   ],
   "source": [
    "### 模型预测生成音乐的过程\n",
    "# 用于存储输出的乐曲序列\n",
    "output_word = []\n",
    "# 指定要生成的乐曲长度\n",
    "length = 500 \n",
    "for i in range(length):\n",
    "    # 由于乐曲序列往往较长，随着预测长度边长，可能会出现信息缺失导致预测效果变差（如重复的旋律等）\n",
    "    # 所以每间隔一段距离在此在输入序列中加入一定辅助乐曲片段作为补充信息\n",
    "    if i % 25 == 0:\n",
    "        indexs = list(random.sample(vocab, 5))\n",
    "        input_index.extend(indexs)\n",
    "    else:\n",
    "        # 预测过程与作诗模型就比较相像了\n",
    "        # 用经预测出的乐曲序列作为输入预测下一个音符存入输出序列中\n",
    "        # 同时每预测出一个音符也要对输入序列进行更新\n",
    "        # 将当前字符与之前的字符拼接形成新的输入序列\n",
    "        x1 = input_index + [0]*(max_len - 1 - len(input_index)) \n",
    "        x1 = [int(i.cpu()) if type(i) != int else i for i in x1]\n",
    "        x1 = torch.LongTensor(np.array([x1], dtype=int))\n",
    "        x1 = Variable(x1).cuda()\n",
    "\n",
    "        x2 = torch.LongTensor(np.array([name_digit.tolist()], dtype=int))\n",
    "        x2 = Variable(x2).cuda()\n",
    "        init_hidden = lstm.initHidden(x2, 9, 1)\n",
    "        pre = lstm(x1, init_hidden)\n",
    "        # 提取最大概率的字符所在的位置，记录其编号\n",
    "        index = torch.argmax(pre) \n",
    "        # 提取上述编号所对应的字符\n",
    "        current_word = [k for k, v in seq2idx.items() if v == index][0] \n",
    "        # 将其存入输出序列\n",
    "        output_word.append(current_word)   \n",
    "        # 同时对输入序列也要更新\n",
    "        input_index.append(index)\n",
    "\n",
    "# 最后展示一下预测出的完整的乐曲序列\n",
    "print(output_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 定义生成音乐函数\n",
    "def seq_to_mid(prediction):\n",
    "    # 偏移累积量，防止数据覆盖\n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "    # 将预测的乐曲序列中的每一个音符符号转换生成对应的Note或chord对象\n",
    "    for data in prediction:\n",
    "        # 如果是和弦chord：列如45.21.78\n",
    "        # data中有.或者有数字\n",
    "        if ('.' in data) or data.isdigit():\n",
    "            # 用.分隔和弦中的每个音\n",
    "            note_in_chord = data.split('.')\n",
    "            # notes列表接收单音\n",
    "            notes = []\n",
    "            for current_note in note_in_chord:\n",
    "                # 把当前音符化成整数，在对应midi_number转换成note\n",
    "                new_note = note.Note(int(current_note))\n",
    "                # 乐器使用钢琴\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "            # 再把notes中的音化成新的和弦\n",
    "            new_chord = chord.Chord(notes)\n",
    "            # 初试定的偏移给和弦的偏移\n",
    "            new_chord.offset = offset\n",
    "            # 把转化好的new_chord弦传到output_notes中\n",
    "            output_notes.append(new_chord)\n",
    "        # 是音符note：\n",
    "        else:\n",
    "            # note直接可以把data变成新的note\n",
    "            new_note = note.Note(data)\n",
    "            new_note.offset = offset\n",
    "            # 乐器用钢琴\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            # 把new_note传到output_notes中\n",
    "            output_notes.append(new_note)\n",
    "        # 每次迭代都将偏移增加，防止交叠覆盖\n",
    "        offset += 0.5\n",
    "    # 将上述转化好的output_notes传到外层的流stream\n",
    "    # 注由于我们只涉及了钢琴一种乐器所以这里stream只由一个part构成即可\n",
    "    # 把上面的循环输出结果传到流\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "    # 将流stream写入midi文件\n",
    "    # 最终输出的文件名是output.mid，格式是mid\n",
    "    midi_stream.write('midi', fp='output.mid')\n",
    "    \n",
    "# 调用函数将输出的音乐列转为midi格式文件存储\n",
    "seq_to_mid(output_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
